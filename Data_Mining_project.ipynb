{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36c9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required packages\n",
    "import pandas as pd\n",
    "#import statistics as stat\n",
    "import sys\n",
    "#import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "#from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be70f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate confusion matrix\n",
    "def confusion_matrix(Y, pred):\n",
    "    \n",
    "    #variables to store TP, FN, FP, FN\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    \n",
    "    for ind, lab in enumerate(Y):\n",
    "        \n",
    "        #when the predicted label and given label is same\n",
    "        if lab == pred[ind]:\n",
    "            if lab == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        \n",
    "        #when the predicted label and given label is not same\n",
    "        else:\n",
    "            if lab == 1:\n",
    "                FN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "                \n",
    "    return [[TP, FN], [FP, TN]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f854fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate accuracy\n",
    "def Accuracy(Y, pred):\n",
    "    \n",
    "    size = len(Y)\n",
    "    \n",
    "    #variable to store the number of records where predicted label and given label is same\n",
    "    num_match = 0\n",
    "    for index, lab in enumerate(Y):\n",
    "        \n",
    "        if lab == pred[index]:\n",
    "            num_match += 1\n",
    "    return num_match/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4deddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate precision\n",
    "def Precision(Y, pred):\n",
    "    \n",
    "    #variables to store true positives and false positives\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    \n",
    "    for index, lab in enumerate(Y):\n",
    "        \n",
    "        if lab == 1.0 and pred[index] == 1.0:\n",
    "            TP += 1\n",
    "        elif lab == 0 and pred[index] == 1.0:\n",
    "            FP += 1\n",
    "    \n",
    "    return TP/(TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c6a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate Recall\n",
    "def Recall(Y, pred):\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    for index, lab in enumerate(Y):\n",
    "        \n",
    "        if lab == 1.0 and pred[index] == 1.0:\n",
    "            TP += 1\n",
    "        elif lab == 1 and pred[index] == 0:\n",
    "            FN += 1\n",
    "    \n",
    "    return TP/(TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03a4599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate F1 score\n",
    "def F1_Score(Y, pred):\n",
    "    prec = Precision(Y, pred)\n",
    "    reca = Recall(Y, pred)\n",
    "    \n",
    "    F1_score = (2*prec*reca)/(prec+reca)\n",
    "    \n",
    "    return F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5b37f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the data\n",
    "df = pd.read_csv(r\"C:\\Users\\Bhavesh Kilaru\\Desktop\\CS5593-Data Mining\\Project\\Data\\mushrooms.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aa0f447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Nulls in each attribute is\n",
      "class 0\n",
      "cap-shape 0\n",
      "cap-surface 0\n",
      "cap-color 0\n",
      "bruises 0\n",
      "odor 0\n",
      "gill-attachment 0\n",
      "gill-spacing 0\n",
      "gill-size 0\n",
      "gill-color 0\n",
      "stalk-shape 0\n",
      "stalk-root 2480\n",
      "stalk-surface-above-ring 0\n",
      "stalk-surface-below-ring 0\n",
      "stalk-color-above-ring 0\n",
      "stalk-color-below-ring 0\n",
      "veil-type 0\n",
      "veil-color 0\n",
      "ring-number 0\n",
      "ring-type 0\n",
      "spore-print-color 0\n",
      "population 0\n",
      "habitat 0\n"
     ]
    }
   ],
   "source": [
    "#printing the number of nulls in each attribute\n",
    "print(\"The number of Nulls in each attribute is\")\n",
    "for col in df.columns:\n",
    "    print(col + \" \"+ str(sum(df[col] == '?')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1e4ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to replace null values in the data\n",
    "#since all values are categorical, the null values will be replaced with mode\n",
    "\n",
    "def replace_null_values(df):\n",
    "    for col in df.columns:\n",
    "        null_count = sum(df[col] == '?')\n",
    "        if null_count > 0:\n",
    "            col_mode = df[col].value_counts().idxmax()\n",
    "            for ind, val in enumerate(df[col]):\n",
    "                if val == \"?\":\n",
    "                    df[col][ind] = col_mode\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82589f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Nulls in data after replacement is\n",
      "class 0\n",
      "cap-shape 0\n",
      "cap-surface 0\n",
      "cap-color 0\n",
      "bruises 0\n",
      "odor 0\n",
      "gill-attachment 0\n",
      "gill-spacing 0\n",
      "gill-size 0\n",
      "gill-color 0\n",
      "stalk-shape 0\n",
      "stalk-root 0\n",
      "stalk-surface-above-ring 0\n",
      "stalk-surface-below-ring 0\n",
      "stalk-color-above-ring 0\n",
      "stalk-color-below-ring 0\n",
      "veil-type 0\n",
      "veil-color 0\n",
      "ring-number 0\n",
      "ring-type 0\n",
      "spore-print-color 0\n",
      "population 0\n",
      "habitat 0\n"
     ]
    }
   ],
   "source": [
    "#replacing Nulls in data\n",
    "df = replace_null_values(df)\n",
    "\n",
    "#printing the number of nulls in data after replacement\n",
    "print(\"The number of Nulls in data after replacement is\")\n",
    "for col in df.columns:\n",
    "    print(col + \" \"+ str(sum(df[col] == '?')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85fa3e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the column Veil-type as it contains only one unique value\n",
    "#this is done as the it contains only one type of value\n",
    "df = df.loc[:, df.columns != 'veil-type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27020ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert categorical attributes to numerical i.e., label encoding\n",
    "def label_encoder(col):\n",
    "    get_unique = col.unique().tolist()\n",
    "    label = []\n",
    "    encoded_val = {}\n",
    "    for uniq_val in get_unique:\n",
    "        encoded_val[uniq_val] = get_unique.index(uniq_val)\n",
    "    for val in col:\n",
    "        label.append(get_unique.index(val))\n",
    "    return label, encoded_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9af7a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalize attributes\n",
    "def normalizer(col):\n",
    "    min_val = min(col)\n",
    "    max_val = max(col)\n",
    "    normalized_vals = []\n",
    "    for val in col:\n",
    "        cal_val = (val - min_val)/(max_val - min_val)\n",
    "        normalized_vals.append(cal_val)\n",
    "    return normalized_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd4dec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data after label encoding and normalization\n",
      "   class  cap-shape  cap-surface  cap-color  bruises   odor  gill-attachment  \\\n",
      "0    0.0        0.0     0.000000   0.000000      0.0  0.000              0.0   \n",
      "1    1.0        0.0     0.000000   0.111111      0.0  0.125              0.0   \n",
      "2    1.0        0.2     0.000000   0.222222      0.0  0.250              0.0   \n",
      "3    0.0        0.0     0.333333   0.222222      0.0  0.000              0.0   \n",
      "4    1.0        0.0     0.000000   0.333333      1.0  0.375              0.0   \n",
      "\n",
      "   gill-spacing  gill-size  gill-color  ...  stalk-surface-above-ring  \\\n",
      "0           0.0        0.0    0.000000  ...                       0.0   \n",
      "1           0.0        1.0    0.000000  ...                       0.0   \n",
      "2           0.0        1.0    0.090909  ...                       0.0   \n",
      "3           0.0        0.0    0.090909  ...                       0.0   \n",
      "4           1.0        1.0    0.000000  ...                       0.0   \n",
      "\n",
      "   stalk-surface-below-ring  stalk-color-above-ring  stalk-color-below-ring  \\\n",
      "0                       0.0                     0.0                     0.0   \n",
      "1                       0.0                     0.0                     0.0   \n",
      "2                       0.0                     0.0                     0.0   \n",
      "3                       0.0                     0.0                     0.0   \n",
      "4                       0.0                     0.0                     0.0   \n",
      "\n",
      "   veil-color  ring-number  ring-type  spore-print-color  population   habitat  \n",
      "0         0.0          0.0       0.00              0.000         0.0  0.000000  \n",
      "1         0.0          0.0       0.00              0.125         0.2  0.166667  \n",
      "2         0.0          0.0       0.00              0.125         0.2  0.333333  \n",
      "3         0.0          0.0       0.00              0.000         0.0  0.000000  \n",
      "4         0.0          0.0       0.25              0.125         0.4  0.166667  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "#encoding and normalizing data i.e, each attribute\n",
    "#getting the encoded indices\n",
    "encoded_indices = {}\n",
    "\n",
    "for i in df.columns:\n",
    "    df[i], temp = label_encoder(df[i])\n",
    "    df[i] = normalizer(df[i])\n",
    "    encoded_indices[i] = temp\n",
    "\n",
    "print(\"The data after label encoding and normalization\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23609108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoded value for each attribute after normalization is\n",
      "{'class': {'p': 0, 'e': 1}, 'cap-shape': {'x': 0, 'b': 1, 's': 2, 'f': 3, 'k': 4, 'c': 5}, 'cap-surface': {'s': 0, 'y': 1, 'f': 2, 'g': 3}, 'cap-color': {'n': 0, 'y': 1, 'w': 2, 'g': 3, 'e': 4, 'p': 5, 'b': 6, 'u': 7, 'c': 8, 'r': 9}, 'bruises': {'t': 0, 'f': 1}, 'odor': {'p': 0, 'a': 1, 'l': 2, 'n': 3, 'f': 4, 'c': 5, 'y': 6, 's': 7, 'm': 8}, 'gill-attachment': {'f': 0, 'a': 1}, 'gill-spacing': {'c': 0, 'w': 1}, 'gill-size': {'n': 0, 'b': 1}, 'gill-color': {'k': 0, 'n': 1, 'g': 2, 'p': 3, 'w': 4, 'h': 5, 'u': 6, 'e': 7, 'b': 8, 'r': 9, 'y': 10, 'o': 11}, 'stalk-shape': {'e': 0, 't': 1}, 'stalk-root': {'e': 0, 'c': 1, 'b': 2, 'r': 3}, 'stalk-surface-above-ring': {'s': 0, 'f': 1, 'k': 2, 'y': 3}, 'stalk-surface-below-ring': {'s': 0, 'f': 1, 'y': 2, 'k': 3}, 'stalk-color-above-ring': {'w': 0, 'g': 1, 'p': 2, 'n': 3, 'b': 4, 'e': 5, 'o': 6, 'c': 7, 'y': 8}, 'stalk-color-below-ring': {'w': 0, 'p': 1, 'g': 2, 'b': 3, 'n': 4, 'e': 5, 'y': 6, 'o': 7, 'c': 8}, 'veil-color': {'w': 0, 'n': 1, 'o': 2, 'y': 3}, 'ring-number': {'o': 0, 't': 1, 'n': 2}, 'ring-type': {'p': 0, 'e': 1, 'l': 2, 'f': 3, 'n': 4}, 'spore-print-color': {'k': 0, 'n': 1, 'u': 2, 'h': 3, 'w': 4, 'r': 5, 'o': 6, 'y': 7, 'b': 8}, 'population': {'s': 0, 'n': 1, 'a': 2, 'v': 3, 'y': 4, 'c': 5}, 'habitat': {'u': 0, 'g': 1, 'm': 2, 'd': 3, 'p': 4, 'w': 5, 'l': 6}}\n"
     ]
    }
   ],
   "source": [
    "#printing the encoded value and the original value for each attribute\n",
    "print(\"The encoded value for each attribute after normalization is\")\n",
    "print(encoded_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce08f4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': {'p': 0, 'e': 1},\n",
       " 'cap-shape': {'x': 0, 'b': 1, 's': 2, 'f': 3, 'k': 4, 'c': 5},\n",
       " 'cap-surface': {'s': 0, 'y': 1, 'f': 2, 'g': 3},\n",
       " 'cap-color': {'n': 0,\n",
       "  'y': 1,\n",
       "  'w': 2,\n",
       "  'g': 3,\n",
       "  'e': 4,\n",
       "  'p': 5,\n",
       "  'b': 6,\n",
       "  'u': 7,\n",
       "  'c': 8,\n",
       "  'r': 9},\n",
       " 'bruises': {'t': 0, 'f': 1},\n",
       " 'odor': {'p': 0,\n",
       "  'a': 1,\n",
       "  'l': 2,\n",
       "  'n': 3,\n",
       "  'f': 4,\n",
       "  'c': 5,\n",
       "  'y': 6,\n",
       "  's': 7,\n",
       "  'm': 8},\n",
       " 'gill-attachment': {'f': 0, 'a': 1},\n",
       " 'gill-spacing': {'c': 0, 'w': 1},\n",
       " 'gill-size': {'n': 0, 'b': 1},\n",
       " 'gill-color': {'k': 0,\n",
       "  'n': 1,\n",
       "  'g': 2,\n",
       "  'p': 3,\n",
       "  'w': 4,\n",
       "  'h': 5,\n",
       "  'u': 6,\n",
       "  'e': 7,\n",
       "  'b': 8,\n",
       "  'r': 9,\n",
       "  'y': 10,\n",
       "  'o': 11},\n",
       " 'stalk-shape': {'e': 0, 't': 1},\n",
       " 'stalk-root': {'e': 0, 'c': 1, 'b': 2, 'r': 3},\n",
       " 'stalk-surface-above-ring': {'s': 0, 'f': 1, 'k': 2, 'y': 3},\n",
       " 'stalk-surface-below-ring': {'s': 0, 'f': 1, 'y': 2, 'k': 3},\n",
       " 'stalk-color-above-ring': {'w': 0,\n",
       "  'g': 1,\n",
       "  'p': 2,\n",
       "  'n': 3,\n",
       "  'b': 4,\n",
       "  'e': 5,\n",
       "  'o': 6,\n",
       "  'c': 7,\n",
       "  'y': 8},\n",
       " 'stalk-color-below-ring': {'w': 0,\n",
       "  'p': 1,\n",
       "  'g': 2,\n",
       "  'b': 3,\n",
       "  'n': 4,\n",
       "  'e': 5,\n",
       "  'y': 6,\n",
       "  'o': 7,\n",
       "  'c': 8},\n",
       " 'veil-color': {'w': 0, 'n': 1, 'o': 2, 'y': 3},\n",
       " 'ring-number': {'o': 0, 't': 1, 'n': 2},\n",
       " 'ring-type': {'p': 0, 'e': 1, 'l': 2, 'f': 3, 'n': 4},\n",
       " 'spore-print-color': {'k': 0,\n",
       "  'n': 1,\n",
       "  'u': 2,\n",
       "  'h': 3,\n",
       "  'w': 4,\n",
       "  'r': 5,\n",
       "  'o': 6,\n",
       "  'y': 7,\n",
       "  'b': 8},\n",
       " 'population': {'s': 0, 'n': 1, 'a': 2, 'v': 3, 'y': 4, 'c': 5},\n",
       " 'habitat': {'u': 0, 'g': 1, 'm': 2, 'd': 3, 'p': 4, 'w': 5, 'l': 6}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eff00957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cap-shape',\n",
       " 'cap-surface',\n",
       " 'cap-color',\n",
       " 'bruises',\n",
       " 'odor',\n",
       " 'gill-attachment',\n",
       " 'gill-spacing',\n",
       " 'gill-size',\n",
       " 'gill-color',\n",
       " 'stalk-shape',\n",
       " 'stalk-root',\n",
       " 'stalk-surface-above-ring',\n",
       " 'stalk-surface-below-ring',\n",
       " 'stalk-color-above-ring',\n",
       " 'stalk-color-below-ring',\n",
       " 'veil-color',\n",
       " 'ring-number',\n",
       " 'ring-type',\n",
       " 'spore-print-color',\n",
       " 'population',\n",
       " 'habitat']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(encoded_indices)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86e399db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The valuees of each catgeory after normalizing \n",
      "{'class': {'p': 0.0, 'e': 1.0}, 'cap-shape': {'x': 0.0, 'b': 0.2, 's': 0.4, 'f': 0.6, 'k': 0.8, 'c': 1.0}, 'cap-surface': {'s': 0.0, 'y': 0.3333333333333333, 'f': 0.6666666666666666, 'g': 1.0}, 'cap-color': {'n': 0.0, 'y': 0.1111111111111111, 'w': 0.2222222222222222, 'g': 0.3333333333333333, 'e': 0.4444444444444444, 'p': 0.5555555555555556, 'b': 0.6666666666666666, 'u': 0.7777777777777778, 'c': 0.8888888888888888, 'r': 1.0}, 'bruises': {'t': 0.0, 'f': 1.0}, 'odor': {'p': 0.0, 'a': 0.125, 'l': 0.25, 'n': 0.375, 'f': 0.5, 'c': 0.625, 'y': 0.75, 's': 0.875, 'm': 1.0}, 'gill-attachment': {'f': 0.0, 'a': 1.0}, 'gill-spacing': {'c': 0.0, 'w': 1.0}, 'gill-size': {'n': 0.0, 'b': 1.0}, 'gill-color': {'k': 0.0, 'n': 0.09090909090909091, 'g': 0.18181818181818182, 'p': 0.2727272727272727, 'w': 0.36363636363636365, 'h': 0.45454545454545453, 'u': 0.5454545454545454, 'e': 0.6363636363636364, 'b': 0.7272727272727273, 'r': 0.8181818181818182, 'y': 0.9090909090909091, 'o': 1.0}, 'stalk-shape': {'e': 0.0, 't': 1.0}, 'stalk-root': {'e': 0.0, 'c': 0.3333333333333333, 'b': 0.6666666666666666, 'r': 1.0}, 'stalk-surface-above-ring': {'s': 0.0, 'f': 0.3333333333333333, 'k': 0.6666666666666666, 'y': 1.0}, 'stalk-surface-below-ring': {'s': 0.0, 'f': 0.3333333333333333, 'y': 0.6666666666666666, 'k': 1.0}, 'stalk-color-above-ring': {'w': 0.0, 'g': 0.125, 'p': 0.25, 'n': 0.375, 'b': 0.5, 'e': 0.625, 'o': 0.75, 'c': 0.875, 'y': 1.0}, 'stalk-color-below-ring': {'w': 0.0, 'p': 0.125, 'g': 0.25, 'b': 0.375, 'n': 0.5, 'e': 0.625, 'y': 0.75, 'o': 0.875, 'c': 1.0}, 'veil-color': {'w': 0.0, 'n': 0.3333333333333333, 'o': 0.6666666666666666, 'y': 1.0}, 'ring-number': {'o': 0.0, 't': 0.5, 'n': 1.0}, 'ring-type': {'p': 0.0, 'e': 0.25, 'l': 0.5, 'f': 0.75, 'n': 1.0}, 'spore-print-color': {'k': 0.0, 'n': 0.125, 'u': 0.25, 'h': 0.375, 'w': 0.5, 'r': 0.625, 'o': 0.75, 'y': 0.875, 'b': 1.0}, 'population': {'s': 0.0, 'n': 0.2, 'a': 0.4, 'v': 0.6, 'y': 0.8, 'c': 1.0}, 'habitat': {'u': 0.0, 'g': 0.16666666666666666, 'm': 0.3333333333333333, 'd': 0.5, 'p': 0.6666666666666666, 'w': 0.8333333333333334, 'l': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "#normalizing indices\n",
    "def normalize_indices(encoded):\n",
    "    \n",
    "    for key in encoded.keys():\n",
    "        min_val = min(encoded[key].values())\n",
    "        max_val = max(encoded[key].values())\n",
    "        \n",
    "        for i in encoded[key].keys():\n",
    "            encoded[key][i] = (encoded[key][i] - min_val)/(max_val - min_val)\n",
    "            \n",
    "    return encoded\n",
    "        \n",
    "encoded_indices = normalize_indices(encoded_indices)\n",
    "print(\"The valuees of each catgeory after normalizing \")\n",
    "print(encoded_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cdd3525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': {'p': 0.0, 'e': 1.0},\n",
       " 'cap-shape': {'x': 0.0, 'b': 0.2, 's': 0.4, 'f': 0.6, 'k': 0.8, 'c': 1.0},\n",
       " 'cap-surface': {'s': 0.0,\n",
       "  'y': 0.3333333333333333,\n",
       "  'f': 0.6666666666666666,\n",
       "  'g': 1.0},\n",
       " 'cap-color': {'n': 0.0,\n",
       "  'y': 0.1111111111111111,\n",
       "  'w': 0.2222222222222222,\n",
       "  'g': 0.3333333333333333,\n",
       "  'e': 0.4444444444444444,\n",
       "  'p': 0.5555555555555556,\n",
       "  'b': 0.6666666666666666,\n",
       "  'u': 0.7777777777777778,\n",
       "  'c': 0.8888888888888888,\n",
       "  'r': 1.0},\n",
       " 'bruises': {'t': 0.0, 'f': 1.0},\n",
       " 'odor': {'p': 0.0,\n",
       "  'a': 0.125,\n",
       "  'l': 0.25,\n",
       "  'n': 0.375,\n",
       "  'f': 0.5,\n",
       "  'c': 0.625,\n",
       "  'y': 0.75,\n",
       "  's': 0.875,\n",
       "  'm': 1.0},\n",
       " 'gill-attachment': {'f': 0.0, 'a': 1.0},\n",
       " 'gill-spacing': {'c': 0.0, 'w': 1.0},\n",
       " 'gill-size': {'n': 0.0, 'b': 1.0},\n",
       " 'gill-color': {'k': 0.0,\n",
       "  'n': 0.09090909090909091,\n",
       "  'g': 0.18181818181818182,\n",
       "  'p': 0.2727272727272727,\n",
       "  'w': 0.36363636363636365,\n",
       "  'h': 0.45454545454545453,\n",
       "  'u': 0.5454545454545454,\n",
       "  'e': 0.6363636363636364,\n",
       "  'b': 0.7272727272727273,\n",
       "  'r': 0.8181818181818182,\n",
       "  'y': 0.9090909090909091,\n",
       "  'o': 1.0},\n",
       " 'stalk-shape': {'e': 0.0, 't': 1.0},\n",
       " 'stalk-root': {'e': 0.0,\n",
       "  'c': 0.3333333333333333,\n",
       "  'b': 0.6666666666666666,\n",
       "  'r': 1.0},\n",
       " 'stalk-surface-above-ring': {'s': 0.0,\n",
       "  'f': 0.3333333333333333,\n",
       "  'k': 0.6666666666666666,\n",
       "  'y': 1.0},\n",
       " 'stalk-surface-below-ring': {'s': 0.0,\n",
       "  'f': 0.3333333333333333,\n",
       "  'y': 0.6666666666666666,\n",
       "  'k': 1.0},\n",
       " 'stalk-color-above-ring': {'w': 0.0,\n",
       "  'g': 0.125,\n",
       "  'p': 0.25,\n",
       "  'n': 0.375,\n",
       "  'b': 0.5,\n",
       "  'e': 0.625,\n",
       "  'o': 0.75,\n",
       "  'c': 0.875,\n",
       "  'y': 1.0},\n",
       " 'stalk-color-below-ring': {'w': 0.0,\n",
       "  'p': 0.125,\n",
       "  'g': 0.25,\n",
       "  'b': 0.375,\n",
       "  'n': 0.5,\n",
       "  'e': 0.625,\n",
       "  'y': 0.75,\n",
       "  'o': 0.875,\n",
       "  'c': 1.0},\n",
       " 'veil-color': {'w': 0.0,\n",
       "  'n': 0.3333333333333333,\n",
       "  'o': 0.6666666666666666,\n",
       "  'y': 1.0},\n",
       " 'ring-number': {'o': 0.0, 't': 0.5, 'n': 1.0},\n",
       " 'ring-type': {'p': 0.0, 'e': 0.25, 'l': 0.5, 'f': 0.75, 'n': 1.0},\n",
       " 'spore-print-color': {'k': 0.0,\n",
       "  'n': 0.125,\n",
       "  'u': 0.25,\n",
       "  'h': 0.375,\n",
       "  'w': 0.5,\n",
       "  'r': 0.625,\n",
       "  'o': 0.75,\n",
       "  'y': 0.875,\n",
       "  'b': 1.0},\n",
       " 'population': {'s': 0.0, 'n': 0.2, 'a': 0.4, 'v': 0.6, 'y': 0.8, 'c': 1.0},\n",
       " 'habitat': {'u': 0.0,\n",
       "  'g': 0.16666666666666666,\n",
       "  'm': 0.3333333333333333,\n",
       "  'd': 0.5,\n",
       "  'p': 0.6666666666666666,\n",
       "  'w': 0.8333333333333334,\n",
       "  'l': 1.0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5820994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the X and Y values from data frame\n",
    "X = df.loc[:, df.columns != 'class']\n",
    "Y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70c55bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4911893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the dataframe into arrays\n",
    "\n",
    "#for training data\n",
    "X_train_arr = np.array(X_train)\n",
    "num_train_records = X_train_arr.shape[0]\n",
    "Y_train_arr = np.array(Y_train)\n",
    "Y_train_arr = np.reshape(Y_train_arr, (num_train_records, 1))\n",
    "\n",
    "#for test data\n",
    "X_test_arr = np.array(X_test)\n",
    "num_test_records = X_test_arr.shape[0]\n",
    "Y_test_arr = np.array(Y_test)\n",
    "Y_test_arr = np.reshape(Y_test_arr, (num_test_records, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfae1528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to calculates the K nearest neighbor\n",
    "class KNN():\n",
    "    \n",
    "    def __init__(self, num_neighbors = 5):\n",
    "        self.neighbors = num_neighbors\n",
    "        self.X_train = None\n",
    "        self.Y_train = None\n",
    "    \n",
    "    #for storing the data\n",
    "    def fit(self, X_train, Y_train):\n",
    "        self.X_train = X_train.values\n",
    "        self.Y_train = Y_train.values\n",
    "    \n",
    "    #prediction using KNN\n",
    "    def predict(self, test):\n",
    "        \n",
    "        #to check if data is a dataframe or an array\n",
    "        if isinstance(test, pd.DataFrame):\n",
    "            X_test = test.values\n",
    "        else:\n",
    "            X_test = test\n",
    "        y_predicted = []\n",
    "\n",
    "        #predicting the the label for for each test example\n",
    "        for test_ex in X_test:\n",
    "\n",
    "            label_pred = self.finding_nearest_neighbors(self.X_train, self.Y_train, test_ex, self.neighbors)\n",
    "\n",
    "            y_predicted.append(label_pred)\n",
    "\n",
    "        return y_predicted\n",
    "    \n",
    "    #finding the label of an example\n",
    "    def finding_nearest_neighbors(self, X_train, Y_train, test_ex, num_neighbors):\n",
    "        \n",
    "        #calculating the distance from each training example\n",
    "        distances = self.distance_caluculator(X_train, test_ex)\n",
    "\n",
    "        #fetching the K nearest neighbors\n",
    "        nearest_neighbors = self.n_nearest_neighbors_finder(distances, num_neighbors)\n",
    "\n",
    "        #getting the label of the example\n",
    "        predicted_label = self.label_caluculator(nearest_neighbors , Y_train)\n",
    "\n",
    "        return predicted_label\n",
    "\n",
    "    #finding the indices of k nearest neighbors\n",
    "    def n_nearest_neighbors_finder(self, distances, num_neighbors):\n",
    "\n",
    "        nearest_neighbor_indices = []\n",
    "\n",
    "        #sorting the distances\n",
    "        smallest_distances = sorted(distances)[:num_neighbors]\n",
    "\n",
    "        for short_dist in smallest_distances:\n",
    "\n",
    "            nearest_neighbor_indices.append(distances.index(short_dist))\n",
    "\n",
    "        return nearest_neighbor_indices\n",
    "\n",
    "    #calculating the label from k near neighbors\n",
    "    def label_caluculator(self, nearest_neighbors , Y_train):\n",
    "\n",
    "        nearest_labels = []\n",
    "        \n",
    "        #fetching thelabels of k nearest neighbors\n",
    "        for ind in nearest_neighbors:\n",
    "\n",
    "            nearest_labels.append(Y_train[ind])\n",
    "\n",
    "        ones_count = nearest_labels.count(1)\n",
    "        zeros_count = nearest_labels.count(0)\n",
    "\n",
    "        #getting the majority vote\n",
    "        if ones_count > zeros_count:\n",
    "            predicted_label = 1\n",
    "        else:\n",
    "            predicted_label = 0\n",
    "\n",
    "        return predicted_label\n",
    "\n",
    "    #calculating the distances from all records in training set to a test example\n",
    "    def distance_caluculator(self, X_train, test_ex):\n",
    "\n",
    "        distances = []\n",
    "\n",
    "        for train_ex in X_train:\n",
    "            \n",
    "            #calculating the distance\n",
    "            dist = np.sqrt(np.sum(np.square(train_ex - test_ex)))\n",
    "\n",
    "            distances.append(dist)\n",
    "\n",
    "        return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92b84ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the Knn classifier\n",
    "clf_Knn = KNN(num_neighbors = 5)\n",
    "\n",
    "#training the model\n",
    "clf_Knn.fit(X_train, Y_train)\n",
    "\n",
    "#prediction on test data\n",
    "y_pred_KNN= clf_Knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55b7371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for KNN when k = 2 is  [[848, 0], [0, 777]]\n"
     ]
    }
   ],
   "source": [
    "#printing the confusion matrix for KNN\n",
    "confusion_matrix_KNN = confusion_matrix(Y_test, y_pred_KNN)\n",
    "print(\"The confusion matrix for KNN when k = 2 is \", confusion_matrix_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a654dfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of mushroom classification on test data using knn when K = 2 is 1.0\n",
      "The Precision of mushroom classification on test data using knn when K = 2 is 1.0\n",
      "The Recall of mushroom classification on test data using knn when K = 2 is 1.0\n",
      "The F1 score of mushroom classification on test data using knn when K = 2 is 1.0\n"
     ]
    }
   ],
   "source": [
    "#calculating the metrics for KNN\n",
    "accuracy_Knn = Accuracy(Y_test, y_pred_KNN)\n",
    "precision_Knn = Precision(Y_test, y_pred_KNN)\n",
    "recall_Knn = Recall(Y_test, y_pred_KNN)\n",
    "F1_Knn = F1_Score(Y_test, y_pred_KNN)\n",
    "print(f\"The accuracy of mushroom classification on test data using knn when K = 5 is {accuracy_Knn}\")\n",
    "print(f\"The Precision of mushroom classification on test data using knn when K = 5 is {precision_Knn}\")\n",
    "print(f\"The Recall of mushroom classification on test data using knn when K = 5 is {recall_Knn}\")\n",
    "print(f\"The F1 score of mushroom classification on test data using knn when K = 5 is {F1_Knn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "407c694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "class Logistic_Regression_Classifier():\n",
    "    \n",
    "    def __init__(self, learning_rate = 0.01, num_episodes = 1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_episodes = num_episodes\n",
    "        self.weights = None\n",
    "        self.bias = np.float(\"0\")\n",
    "        self.cost = []\n",
    "    \n",
    "    #training the model\n",
    "    def fit(self, X_train, Y_train):\n",
    "        num_attributes = X_train.shape[1]\n",
    "        self.weights = np.zeros((1, num_attributes))\n",
    "        \n",
    "        self.propagate(X_train, Y_train)\n",
    "    \n",
    "    #sigmoid function\n",
    "    def sigmoid(self, X, w, b):\n",
    "        z = np.dot(X, w.T) + b\n",
    "        s = 1 / (1 + np.exp(-z))\n",
    "        return s\n",
    "    \n",
    "    #predicting the labels and adjusting the weights\n",
    "    def propagate(self, X_train, Y_train):\n",
    "        \n",
    "        m = X_train.shape[0]\n",
    "        \n",
    "        for i in range(self.num_episodes):\n",
    "            \n",
    "            #forward propagation - predicting for training examples\n",
    "            y_predicted = self.sigmoid(X_train, self.weights, self.bias)\n",
    "            \n",
    "            #cost during an epoch\n",
    "            temp_cost = (-(Y_train * np.log(y_predicted)) - ((1-Y_train)*np.log(1- y_predicted))).mean()\n",
    "            \n",
    "            self.cost.append(temp_cost)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                \n",
    "                print(f\"After {i} episodes, the cost is {temp_cost}\")\n",
    "            \n",
    "            #gradient descent - change in weights and bias\n",
    "            dw, db = self.gradient_descent(X_train, Y_train, y_predicted, m)\n",
    "            \n",
    "            #changing the weights\n",
    "            self.weights -= self.learning_rate * dw.T\n",
    "            \n",
    "            #changing the bias\n",
    "            self.bias -= self.learning_rate * db\n",
    "    \n",
    "    #gradient descent - to get the change in weights and bias\n",
    "    def gradient_descent(self, X_train, Y_train, Y_predicted, m):\n",
    "        \n",
    "        dz = Y_predicted - Y_train\n",
    "        \n",
    "        dw = (1/m) * np.dot(X_train.T, dz)\n",
    "        \n",
    "        db = (1/m)*np.sum(dz)\n",
    "        \n",
    "        return dw, db\n",
    "            \n",
    "    #for predicting an example        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        y_pred = self.sigmoid(X, self.weights, self.bias).round()\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    #for plotting the cost\n",
    "    def plot_cost(self):\n",
    "        \n",
    "        plt.plot(range(self.num_episodes), self.cost)\n",
    "        plt.xlabel(\"Number of epochs\")\n",
    "        plt.ylabel(\"Cost\")\n",
    "        #plt.title(f\"number of epochs vs Cost for Logistic Regression when number of epochs is {self.num_episodes} and learning rate is {self.learning_rate}\")\n",
    "        plt.title(\"number of epochs vs Cost for Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "361a8714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavesh Kilaru\\AppData\\Local\\Temp\\ipykernel_89252\\3714523605.py:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self.bias = np.float(\"0\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 episodes, the cost is 0.6931471805599453\n",
      "After 100 episodes, the cost is 0.47750465582879953\n",
      "After 200 episodes, the cost is 0.3873954206782888\n",
      "After 300 episodes, the cost is 0.34027453380449635\n",
      "After 400 episodes, the cost is 0.31121845093191386\n",
      "After 500 episodes, the cost is 0.2911412347782134\n",
      "After 600 episodes, the cost is 0.2761277038603135\n",
      "After 700 episodes, the cost is 0.2642586897606963\n",
      "After 800 episodes, the cost is 0.25449481408416463\n",
      "After 900 episodes, the cost is 0.24622660751321312\n",
      "After 1000 episodes, the cost is 0.2390726252650657\n",
      "After 1100 episodes, the cost is 0.23278075869422452\n",
      "After 1200 episodes, the cost is 0.22717651220734006\n",
      "After 1300 episodes, the cost is 0.2221342740204896\n",
      "After 1400 episodes, the cost is 0.21756054866592944\n",
      "After 1500 episodes, the cost is 0.21338373997227778\n",
      "After 1600 episodes, the cost is 0.2095476834576188\n",
      "After 1700 episodes, the cost is 0.2060074097630125\n",
      "After 1800 episodes, the cost is 0.20272628238825277\n",
      "After 1900 episodes, the cost is 0.19967400890916182\n",
      "After 2000 episodes, the cost is 0.19682522348843834\n",
      "After 2100 episodes, the cost is 0.19415845301971998\n",
      "After 2200 episodes, the cost is 0.1916553472409152\n",
      "After 2300 episodes, the cost is 0.1893000946134637\n",
      "After 2400 episodes, the cost is 0.1870789716733463\n",
      "After 2500 episodes, the cost is 0.1849799901253973\n",
      "After 2600 episodes, the cost is 0.1829926167743817\n",
      "After 2700 episodes, the cost is 0.1811075486009037\n",
      "After 2800 episodes, the cost is 0.17931653019320204\n",
      "After 2900 episodes, the cost is 0.17761220413901233\n",
      "After 3000 episodes, the cost is 0.17598798737049887\n",
      "After 3100 episodes, the cost is 0.17443796816435805\n",
      "After 3200 episodes, the cost is 0.17295681974059646\n",
      "After 3300 episodes, the cost is 0.17153972731794312\n",
      "After 3400 episodes, the cost is 0.17018232616635667\n",
      "After 3500 episodes, the cost is 0.1688806487126615\n",
      "After 3600 episodes, the cost is 0.16763107914921185\n",
      "After 3700 episodes, the cost is 0.1664303142994824\n",
      "After 3800 episodes, the cost is 0.165275329731372\n",
      "After 3900 episodes, the cost is 0.1641633502952186\n",
      "After 4000 episodes, the cost is 0.16309182441109732\n",
      "After 4100 episodes, the cost is 0.16205840154779835\n",
      "After 4200 episodes, the cost is 0.16106091243061896\n",
      "After 4300 episodes, the cost is 0.16009735159175997\n",
      "After 4400 episodes, the cost is 0.15916586193952745\n",
      "After 4500 episodes, the cost is 0.15826472107362982\n",
      "After 4600 episodes, the cost is 0.15739232911591025\n",
      "After 4700 episodes, the cost is 0.15654719786062865\n",
      "After 4800 episodes, the cost is 0.1557279410773056\n",
      "After 4900 episodes, the cost is 0.15493326582325598\n",
      "After 5000 episodes, the cost is 0.1541619646431535\n",
      "After 5100 episodes, the cost is 0.15341290854997133\n",
      "After 5200 episodes, the cost is 0.1526850406960069\n",
      "After 5300 episodes, the cost is 0.1519773706548734\n",
      "After 5400 episodes, the cost is 0.15128896924569094\n",
      "After 5500 episodes, the cost is 0.15061896383954732\n",
      "After 5600 episodes, the cost is 0.1499665340958568\n",
      "After 5700 episodes, the cost is 0.1493309080827377\n",
      "After 5800 episodes, the cost is 0.14871135874111843\n",
      "After 5900 episodes, the cost is 0.14810720065710586\n",
      "After 6000 episodes, the cost is 0.14751778711132724\n",
      "After 6100 episodes, the cost is 0.1469425073775806\n",
      "After 6200 episodes, the cost is 0.14638078424628354\n",
      "After 6300 episodes, the cost is 0.1458320717509587\n",
      "After 6400 episodes, the cost is 0.14529585307839946\n",
      "After 6500 episodes, the cost is 0.1447716386452635\n",
      "After 6600 episodes, the cost is 0.14425896432569252\n",
      "After 6700 episodes, the cost is 0.14375738981617955\n",
      "After 6800 episodes, the cost is 0.14326649712534217\n",
      "After 6900 episodes, the cost is 0.14278588917752308\n",
      "After 7000 episodes, the cost is 0.14231518852026073\n",
      "After 7100 episodes, the cost is 0.14185403612666658\n",
      "After 7200 episodes, the cost is 0.14140209028462555\n",
      "After 7300 episodes, the cost is 0.14095902556552167\n",
      "After 7400 episodes, the cost is 0.14052453186589062\n",
      "After 7500 episodes, the cost is 0.14009831351602206\n",
      "After 7600 episodes, the cost is 0.13968008845009613\n",
      "After 7700 episodes, the cost is 0.13926958743293338\n",
      "After 7800 episodes, the cost is 0.1388665533388882\n",
      "After 7900 episodes, the cost is 0.1384707404788164\n",
      "After 8000 episodes, the cost is 0.1380819139714085\n",
      "After 8100 episodes, the cost is 0.13769984915550645\n",
      "After 8200 episodes, the cost is 0.13732433104031436\n",
      "After 8300 episodes, the cost is 0.13695515379067832\n",
      "After 8400 episodes, the cost is 0.13659212024485046\n",
      "After 8500 episodes, the cost is 0.13623504146236814\n",
      "After 8600 episodes, the cost is 0.13588373629987544\n",
      "After 8700 episodes, the cost is 0.13553803101289358\n",
      "After 8800 episodes, the cost is 0.13519775888170552\n",
      "After 8900 episodes, the cost is 0.13486275985967067\n",
      "After 9000 episodes, the cost is 0.13453288024241616\n",
      "After 9100 episodes, the cost is 0.13420797235647497\n",
      "After 9200 episodes, the cost is 0.13388789426605174\n",
      "After 9300 episodes, the cost is 0.13357250949669824\n",
      "After 9400 episodes, the cost is 0.13326168677477393\n",
      "After 9500 episodes, the cost is 0.13295529978165124\n",
      "After 9600 episodes, the cost is 0.13265322692170287\n",
      "After 9700 episodes, the cost is 0.13235535110318059\n",
      "After 9800 episodes, the cost is 0.13206155953115858\n",
      "After 9900 episodes, the cost is 0.13177174351177612\n"
     ]
    }
   ],
   "source": [
    "#creating the logistic regression classifier\n",
    "LR_clf = Logistic_Regression_Classifier(num_episodes = 10000, learning_rate = 0.05)\n",
    "\n",
    "#training the model\n",
    "LR_clf.fit(X_train_arr, Y_train_arr)\n",
    "\n",
    "#predicting the test dara\n",
    "Y_pred_LR = LR_clf.predict(X_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15110a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for Logistic Regression is  [[795, 53], [35, 742]]\n"
     ]
    }
   ],
   "source": [
    "#printing the confusion matrix for logistic regression\n",
    "confusion_matrix_LR = confusion_matrix(Y_test, Y_pred_LR)\n",
    "print(\"The confusion matrix for Logistic Regression is \", confusion_matrix_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b135733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[742,  35],\n",
       "       [ 53, 795]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix as CM\n",
    "CM(Y_test, Y_pred_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6130ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of mushroom classification on test data using Logistic Regression is 0.9458461538461539\n",
      "The Precision of mushroom classification on test data using Logistic Regression when K = 2 is 0.9578313253012049\n",
      "The Recall of mushroom classification on test data using Logistic Regression when K = 2 is 0.9375\n",
      "The F1 score of mushroom classification on test data using Logistic Regression when K = 2 is 0.9475566150178785\n"
     ]
    }
   ],
   "source": [
    "#calculating the metrics for Logistic Regression\n",
    "accuracy_LR = Accuracy(Y_test, Y_pred_LR)\n",
    "precision_LR = Precision(Y_test, Y_pred_LR)\n",
    "recall_LR = Recall(Y_test, Y_pred_LR)\n",
    "F1_LR = F1_Score(Y_test, Y_pred_LR)\n",
    "print(f\"The accuracy of mushroom classification on test data using Logistic Regression is {accuracy_LR}\")\n",
    "print(f\"The Precision of mushroom classification on test data using Logistic Regression when K = 2 is {precision_LR}\")\n",
    "print(f\"The Recall of mushroom classification on test data using Logistic Regression when K = 2 is {recall_LR}\")\n",
    "print(f\"The F1 score of mushroom classification on test data using Logistic Regression when K = 2 is {F1_LR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7eb9fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LR_clf.plot_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd599b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class that implements deep network\n",
    "class DeepNeuralNetwork():\n",
    "    def __init__(self, sizes, batch_size = 100, epochs=10, learning_rate = 0.1):\n",
    "        self.sizes = sizes\n",
    "        self.batch_size = batch_size\n",
    "        self.l_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.loss = []\n",
    "        \n",
    "        # Save all weights\n",
    "        self.params = self.initialize()\n",
    "        # Save all intermediate values, i.e. activations\n",
    "        self.cache = {}\n",
    "        \n",
    "    #method to calculate sigmoid and its derivative\n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        '''\n",
    "            Forward path:\n",
    "            Ïƒ(x) = 1 / 1+exp(-z)\n",
    "            \n",
    "            Backward path:\n",
    "            âˆ‡Ïƒ(x) = exp(-z) / (1+exp(-z))^2\n",
    "        '''\n",
    "        if derivative:\n",
    "            return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    #to initialize weights - weights with random number and bias with zero\n",
    "    def initialize(self):\n",
    "        # number of nodes in each layer\n",
    "        input_layer=self.sizes[0]\n",
    "        hidden_layer=self.sizes[1]\n",
    "        output_layer=self.sizes[2]\n",
    "        \n",
    "        params = {\n",
    "            \"W1\": np.random.randn(hidden_layer, input_layer) * 0.01,\n",
    "            \"b1\": np.zeros((hidden_layer, 1)) * np.sqrt(1./input_layer),\n",
    "            \"W2\": np.random.randn(output_layer, hidden_layer) * 0.01,\n",
    "            \"b2\": np.zeros((output_layer, 1)) * np.sqrt(1./hidden_layer)\n",
    "        }\n",
    "        return params\n",
    "    \n",
    "    #feed forward\n",
    "    def feed_forward(self, x):\n",
    "        '''\n",
    "            y = Ïƒ(wX + b)\n",
    "        '''\n",
    "        self.cache[\"X\"] = x\n",
    "        self.cache[\"Z1\"] = np.matmul(self.params[\"W1\"], self.cache[\"X\"].T) + self.params[\"b1\"]\n",
    "        self.cache[\"A1\"] = self.sigmoid(self.cache[\"Z1\"])\n",
    "        self.cache[\"Z2\"] = np.matmul(self.params[\"W2\"], self.cache[\"A1\"]) + self.params[\"b2\"]\n",
    "        self.cache[\"A2\"] = self.sigmoid(self.cache[\"Z2\"])\n",
    "        return self.cache[\"A2\"]\n",
    "    \n",
    "    #backward propagation - to get the change in weights and bias for each layer\n",
    "    def back_propagate(self, y, output):\n",
    "        '''\n",
    "            This is the backpropagation algorithm, for calculating the updates\n",
    "            of the neural network's parameters.\n",
    "        '''\n",
    "        current_batch_size = y.shape[0]\n",
    "        \n",
    "        #for output layer\n",
    "        dZ2 = output - y.T\n",
    "        dW2 = (1./current_batch_size) * np.matmul(dZ2, self.cache[\"A1\"].T)\n",
    "        db2 = (1./current_batch_size) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "        \n",
    "        #for hidden layer\n",
    "        dA1 = np.matmul(self.params[\"W2\"].T, dZ2)\n",
    "        dZ1 = dA1 * self.sigmoid(self.cache[\"Z1\"], derivative=True)\n",
    "        dW1 = (1./current_batch_size) * np.matmul(dZ1, self.cache[\"X\"])\n",
    "        db1 = (1./current_batch_size) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "        self.grads = {\"W1\": dW1, \"b1\": db1, \"W2\": dW2, \"b2\": db2}\n",
    "        return self.grads\n",
    "    \n",
    "    #method to get the loss\n",
    "    def cross_entropy_loss(self, y, output):\n",
    "        '''\n",
    "            L(y, yÌ‚) = âˆ’âˆ‘ylog(yÌ‚).\n",
    "        '''\n",
    "        l_sum = np.sum(np.multiply(y.T, np.log(output)))\n",
    "        m = y.shape[0]\n",
    "        l = -(1./m) * l_sum\n",
    "        return l\n",
    "    \n",
    "    #stochastic gradient descent - to adjust weights and bias\n",
    "    def sgd(self, l_rate):\n",
    "        '''\n",
    "            Stochatic Gradient Descent (SGD):\n",
    "            Î¸^(t+1) <- Î¸^t - Î·âˆ‡L(y, yÌ‚)\n",
    "        '''\n",
    "        for key in self.params:\n",
    "                self.params[key] = self.params[key] - l_rate * self.grads[key]\n",
    "    \n",
    "    #method to get the accuracy\n",
    "    def accuracy(self, y, output):\n",
    "        return np.mean(np.argmax(y, axis=-1) == np.argmax(output.T, axis=-1))\n",
    "\n",
    "    #method to train the network\n",
    "    def train(self, x_train, y_train, epochs, batch_size, l_rate):\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        num_batches = x_train.shape[0] // self.batch_size\n",
    "        \n",
    "        start_time = time.time()\n",
    "        template = \"Epoch {}: {:.2f}s, train acc={:.2f}, train loss={:.2f}\"\n",
    "        \n",
    "        # Train\n",
    "        for i in range(self.epochs):\n",
    "            # Shuffling the training data\n",
    "            permutation = np.random.permutation(x_train.shape[0])\n",
    "            x_train_shuffled = x_train[permutation]\n",
    "            y_train_shuffled = y_train[permutation]\n",
    "\n",
    "            for j in range(num_batches):\n",
    "                \n",
    "                # Getting the batch\n",
    "                begin = j * self.batch_size\n",
    "                end = min(begin + self.batch_size, x_train.shape[0]-1)\n",
    "                x = x_train_shuffled[begin:end]\n",
    "                y = y_train_shuffled[begin:end]\n",
    "                \n",
    "                # Forward\n",
    "                output = self.feed_forward(x)\n",
    "                # Backpropagating for adjusting the weights\n",
    "                grad = self.back_propagate(y, output)\n",
    "                # Optimize\n",
    "                self.sgd(l_rate=l_rate)\n",
    "\n",
    "            # Evaluate performance\n",
    "            # Training data\n",
    "            output = self.feed_forward(x_train)\n",
    "            train_acc = self.accuracy(y_train, output)\n",
    "            train_loss = self.cross_entropy_loss(y_train, output)\n",
    "            self.loss.append(train_loss)\n",
    "            if i % 100 == 0:\n",
    "                print(template.format(i+1, time.time()-start_time, train_acc, train_loss))\n",
    "            \n",
    "    #training the model        \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.train(x_train, y_train, self.epochs, self.batch_size, self.l_rate)\n",
    "    \n",
    "    #to predict an example\n",
    "    def predict(self, x_test):\n",
    "        output = self.feed_forward(x_test)\n",
    "        return output[1].round()\n",
    "    \n",
    "    #for plotting the loss\n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.loss)\n",
    "        plt.xlabel(\"Number of epochs\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.title(\"Number of epochs vs loss for Artificial neural network classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51bd73fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavesh Kilaru\\AppData\\Local\\Temp\\ipykernel_89252\\786653118.py:4: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  return np.array(x[:, None] == np.arange(k), dtype)\n"
     ]
    }
   ],
   "source": [
    "#one hot encoder\n",
    "def one_hot(x, k, dtype=np.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "    return np.array(x[:, None] == np.arange(k), dtype)\n",
    "\n",
    "Y_train_one_hot = one_hot(Y_train.astype('int32'), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd11ae05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 0.04s, train acc=0.52, train loss=0.69\n",
      "Epoch 101: 2.08s, train acc=0.98, train loss=0.07\n",
      "Epoch 201: 4.13s, train acc=1.00, train loss=0.03\n",
      "Epoch 301: 6.20s, train acc=1.00, train loss=0.01\n",
      "Epoch 401: 8.24s, train acc=1.00, train loss=0.01\n"
     ]
    }
   ],
   "source": [
    "#creating the Deep Neural network object\n",
    "ANN_Clf = DeepNeuralNetwork(sizes=[X.shape[1], 10, 2], epochs = 500)\n",
    "\n",
    "#training the model\n",
    "ANN_Clf.fit(X_train_arr, Y_train_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84a84752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the test data using KNN\n",
    "pred_Ann = ANN_Clf.predict(X_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e137032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[848, 0], [0, 777]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test, pred_Ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f8c8bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for ANN is  [[848, 0], [0, 777]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for ANN\n",
    "confusion_matrix_ANN = confusion_matrix(Y_test, pred_Ann)\n",
    "print(\"The confusion matrix for ANN is \", confusion_matrix_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e39d1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of mushroom classification on test data using Artificial Neural Networks classifier is 1.0\n",
      "The Precision of mushroom classification on test data using Artificial Neural Networks classifier  is 1.0\n",
      "The Recall of mushroom classification on test data using Artificial Neural Networks classifier  is 1.0\n",
      "The F1 score of mushroom classification on test data using Artificial Neural Networks classifier is 1.0\n"
     ]
    }
   ],
   "source": [
    "#calculating the metrics for Artificial Neural Networks\n",
    "accuracy_ANN = Accuracy(Y_test, pred_Ann)\n",
    "precision_ANN = Precision(Y_test, pred_Ann)\n",
    "recall_ANN = Recall(Y_test, pred_Ann)\n",
    "F1_ANN = F1_Score(Y_test, pred_Ann)\n",
    "print(f\"The accuracy of mushroom classification on test data using Artificial Neural Networks classifier is {accuracy_ANN}\")\n",
    "print(f\"The Precision of mushroom classification on test data using Artificial Neural Networks classifier  is {precision_ANN}\")\n",
    "print(f\"The Recall of mushroom classification on test data using Artificial Neural Networks classifier  is {recall_ANN}\")\n",
    "print(f\"The F1 score of mushroom classification on test data using Artificial Neural Networks classifier is {F1_ANN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8332422b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEWCAYAAAC0Q+rDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAwHklEQVR4nO3deZwdVZn/8c+3by9JJ52NdCDpbCxhFxACjDvubAqOC+CCiA6D/nB0xg1Hx3GZGXV0ZtxFRMR1kHEDEQccZVFRSJCwEwgBzAbphOxLp5fn90edTio3t5ckXd3pvt/369WvruVU1XPq1r3PPafqVikiMDMzK0LNUAdgZmYjl5OMmZkVxknGzMwK4yRjZmaFcZIxM7PCOMmYmVlhRkySkXSVpH8Zom1L0rclrZF051DEUG4o90c5SRdI+v0gbu81kpZI2ijp2YO13b5I+pWkt+bG/0XSKklPSZqZ4i31sY4XSFrYz+0N6n7fG5JC0iFDHcfekPSEpJft5To+Lun7AxVThfU/IOmUNLzT59buHFu7o3agV9hN0hPAaOCgiNiUpr0DeHNEnFLUdofI84GXA9O762pD6vPAJRFx7UCuVNJVwJuBmRGxvI+yHwcOiYg3d0+LiNNy82cA7wNmRcTKNHlsXzFExO+Aw3Y7+Col6Rbg+xFxxVDHsi+IiKNyo5U+twb82Cq6JVMLvKfgbQy4vr5NVjALeMIJZp8xC3hgTxbs6bWXNAZ4LbAOeFMf6+jPl7dZwOpcghmx+rk/hq1hXL8B+9zqbR8UnWQ+B7xf0oTyGZJmpyZybW7aLam1093U/4Ok/5K0VtJiSc9N05dIWpnvekgmS/q1pA2SbpU0K7fuw9O8ZyQtlPSG3LyrJH1d0g2SNgEvrhDvNEnXpeUXSfqbNP3twBXAc1J3xycq7QhJF0p6KDVNbyyLLST9XarjKkmfk1ST5tVI+qikJ1OdvytpfG7Z50u6Pe2jJZIuyG12oqRfpv1xh6SD0zJK+3WlpHWS7pV0dIWYz5U0v2za30u6Lg2fLunBtP5lkt5fqe4V1vtcSfPStudJem5u3gVpP2yQ9LikN6Xph6TXdF3aRz+qsN4GSRuBEnCPpMfS9CPSsbVWWXfBq3PL9PnaJ68F1gKfBHY67pR1cfxY0vclrQcuBv4ROCcdE/ekcrdIeoeyLpVfA9PS/KvK3w+SJinryliejpmfp+mnSFqa2/alkh5L++tBSa/p52vQvb23SvpL2qcfyc2vya17taRrJE2qFEOatr2rqML+uEDSSZL+mF6DFZK+Iqm+n7HeIulTyj4PNki6SdLk3Py/yr0H7tGO7qB/BV4AfCXt569I+oSkL6f5dZI2Sfr3ND5a0lZJE9P4q9PxsjbFcERZfT8k6V5gk8o+ZJV93jwu6dwe6nSUdnwePS3pH3so9z/KulPXSbpN0lG5eRXff5ImS7o+xf2MpN9px+fJE5JepgqfWxWOrWmSfiKpNdXl73LzdnmNe3wBI6KQP+AJ4GXAT4F/SdPeAdyShmcDAdTmlrkFeEcavgDoAN5G9qHxL8BfgK8CDcArgA3A2FT+qjT+wjT/i8Dv07wxwJK0rlrgeGAVcFRu2XXA88gS76gK9bkV+BowCjgOaAVemov1973si7OBRcARafsfBW7PzQ/gZmASMBN4JLcfLkzLHkTWnfJT4Htp3sxU5/OAOmA/4LhcnZ4BTkrb/AFwdZr3SuAuYAKgFNfUCnE3pvXPyU2bB5ybhlcAL0jDE4Hje6j/9v2T6rgGeEuK67w0vl96ndYDh6WyU3Ov0X8DH+l+fYDn97K/g6yrirRfFpF96NcDL0l1Oiy3n3p97VO53wD/DuxPdlwen5v3caA9vc41ZN3EHyfrpsmv45bc63oKsDQ3bza59wPwS+BHab/WAS/qYbnXA9PSds8BNnW/lvRyXOa2980U77FAG3BEmv9e4E/AdLL30zeA/64UQ/793sv+OAH4q/SazwYeAt5b6TWrEOstwGPAoWldtwCfSfNagNXA6WlbL0/jzeX7PI2/BLgvDT83rfeO3Lx70vChaV++PO3/D5IdR/W5+i4AZgCjyz7zjif7rDqzh/o0kb133kd2LDcBJ+f23fdzZS9M8xuALwALcvMqvv+ATwOXpbjryBKtKrxOF5A7PvKva9qXdwEfI3vfHAQsBl7Z02vc4/uxPwljT/5yO/xosjdxM7ufZB7NzXtWKr9/btpqdv5QvTo3byzQmQ6Cc4DflcX3DeCfc8t+t5e6zEjraspN+zRwVV9v5jT/V8Dbc+M1wGay/nhSvU7NzX8X8Jvch9u7cvMOSy9uLfBh4Gc9bPMq4Irc+OnAw7k30yNkb/qaPl7H7wMfS8NzyD6gG9P4X4C/Bcb1sY7t+4csudxZNv+PqcwYstbCa8sPWuC7wOVk/cd9HXv5JPMC4Kl8PckS1sf789qnMjOBrtyxdiPwxdz8jwO3lS3zcfYwyZAl1y5gYoVYdlquwvwFwFl9HZe57U3PTbuTHV8gHiJ9iUrjU3PH3S4xsGuSua2nGFOZ95I7duk7yXy07P3xv2n4Q6QvXbn5NwJvLd/naXw0sJXsS82lZF8+lpJ9XnwC+FIq90/ANWXv2WXAKbn6XlhhH3wire/FvdT9PODuHubtctzk5k1I+2l8b+8/stb2tZX2J/1PMicDfylb9sPAt/v7Gnf/FX51WUTcD1xP9oLurqdzw1vS+sqn5U+WLsltdyPZN/lpZH2PJ6fm41pJa8n61Q+otGwF04BnImJDbtqTZN+i+mMW8MXctp8ha0Hkl89v/8m0ze5tP1k2r5bsG/UMsm9iPXkqN7yZtK8i4rfAV8hahU9LulzSuB7W8UOyNwXAG4GfR8TmNP5asuT1pLKurOf0Eku38vp016klsr7hc8i6m1Yo6+o7PJX5INk+uzN1YVzYj211b29JRHSVby833ttrD1lifCgiFqTxHwBvlFS3G+vYHTPIjrc1fRWUdL6kBblj62hgch+L5VU8RsiO2Z/l1vsQ2Ret/fu53p32h6RDUxfOU6l75d8GMM7Xl723n0+WFHcREVuA+cCLyHo9bgVuJ2vJviiNQ9lxmo6fJfR93FxM1ktxcy916et9C2TnByV9JnVZridLELBjv/X0/vscWavrJmVdz3vy2TuLrDs3v1//kZ1f/34d84N1CfM/A3/Dzi9Q98mmxty0/If+npjRPSBpLFnXzHKynXFrREzI/Y2NiHfmlo1e1rscmCSpKTdtJtk3m/5YAvxt2fZHR8TtlWJP6+6+emk52Quen9dBloCXAAf3M4adRMSXIuIE4CiyroEP9FD0JrJzXceRJZsf5tYxLyLOAqYAPweu6cemy+sDuX0ZETdGxMvJPiQeJuvOISKeioi/iYhpZN/evqb+XfK6HJjR3Sddvr3uqvSxjvOBg9IH5FPAf5K90U/LlSlfR1/r7M0SsuNtQm+FlJ3X+yZwCbBfREwA7idLxntrCXBa2TE7KiKWkb13t79vlV0s0Vy2fHn9v072es6JiHFkH1gDFef3yuIcExGf6SEOyBLJS4Bnk3X/3krWhXwScFsqs9NxKklk79G+jpuLgZmS/quPmPvzvn0jcBZZj9B4stYnpP3W0/svIjZExPsi4iDgVcA/SHppP7ZXHuPjZfu1KSJOz5Xp1zE+KEkmIhaR9S//XW5aK9kL9uaUsS9kDz8wc05XdiK8HvgUWV/rErKW1KGS3pJO9tVJOjF/Iq+P+JeQfdv5tKRRko4B3k72jbY/LgM+3H3STtJ4Sa8vK/MBSROVXdr6HrL9BVnXzt9LOjAlzn8DfhQRHWn7L5P0Bkm1kvZLyaBXqe4np2/im8i6Dzp7qHsH8GOyb0eTyE5YI6le0pskjY+IdrJzKRXXUeYGstfijSnmc4Ajgesl7a/sZOsYsvMDG7vXKen1kqandawhO8D7s707Uh0/mF73U8jeeFf3Y1nSt8ODyT6Ajkt/R5Ml27f2sujTwOyy5NYvEbGCrIv1a+mYqJP0wgpFx5Dth9YU69tSbAPhMuBfUyJDUrOks9K8R4BRks5Ix9BHyc4Z9KaJ7BjZmFqn7+yjfH99H3iVpFemz5FR6QR297HyNNn5hLxbyb44PBgR20hdamQfqq2pzDXAGZJemur4PrJj8nZ6twE4FXihpM/0UOZ64ABJ71V2sUqTpJMrlGtK21xNltT/rXtGb+8/SWcqu1BGuen9ea/k3QmsV3Zxw+i0b4+WdOJurmdQf4z5SbI3Rd7fkH2DXk32jbqvF7AvPyRrNT1DdqLxTZBldrILBc4l+4byFPBZ+n5j5J1H9k1iOfAzsvM5v+7PghHxs7S9q1Oz9352/hYMWR/qXWR96r8EvpWmXwl8j+wb1uNkCeHdab1/IWsuvy/VeQHZCdy+jCP7BryGrEtgNdlvS3ryQ7JvU/+Tkk63twBPaMcVVW+utHBeRKwGzkwxrybrBjszIlaRHY/vI9vHz5B1X7wrLXoicIeyq8euA94TEY/3Y3vbgFeT7e9VZBdvnB8RD/e1bPJW4NqIuC+1pp6KiKfILiw5U+mKqwr+J/1fLenP/dxW3lvIzoE8DKwkO4exk4h4EPgPsnNaT5Odt/zDHmyrki+S7eebJG0guwjg5LTddWSvyxVkXxQ3kZ2H6M37yb6ZbyA79na5OnBPpC+AZ5G1jFrJvoF/gB2fbV8EXqfsCr0vpWm3k52b6W61PEj2vrott96FZMfzl8mOm1cBr0rHU18xrSW7YOA0SZ+qMH9Dmv8qss+iR6l8VeN3yd6fy1KMfyqb39P7bw7wf2Rf0v4IfC0ibukr7rIYO1N8x5F97qwie73H7856YMcVBzaEJAVZN8KioY7FzGwgjZjbypiZ2b7HScbMzArj7jIzMyuMWzJmZlaYYXdjt8mTJ8fs2bOHOgwzs2HlrrvuWhUR5b9nKtywSzKzZ89m/vz5fRc0M7PtJJXfaWNQuLvMzMwK4yRjZmaFcZIxM7PCFJpkJJ2q7AFhiyrdCVTSB5TdQXaBpPsldfZymw4zMxtmCksy6c6sXyW7Z9SRwHmSjsyXiYjPRcRxEXEc2bMKbo2IZ4qKyczMBleRLZmTgEURsTjdVO5qshvZ9eQ8sjsOm5nZCFFkkmlh54faLKWHh3xJaiS7PfZPeph/kaT5kua3trZWKmJmZvugIpNMpQcS9XQPm1cBf+ipqywiLo+IuRExt7l5z35LtPCpDfznTQv52d1Lae/s6nsBMzPba0X+GHMpOz/tcTo7nvZY7lwK7ipbtHIjX/ptdif9H9+1lO9deDI1NQPxYD4zM+tJkS2ZecCc9ETHerJEcl15IUnjyR5OdW2BsXDGMVN5/NOnc+lph/OHRauZ94SvLzAzK1phSSY9QfES4EbgIeCaiHhA0sWSLs4VfQ1wU0RsKiqWbpI4/zmzaKwvccN9K4renJlZ1Sv03mURcQPZM93z0y4rG78KuKrIOPIa62uZM2Usi1cVntPMzKpeVf7if/qkRpY8s3mowzAzG/GqM8lMHM2ytVvo7PID28zMilSVSWbGxEbaO4OVG7YOdShmZiNaVSaZlgmjAVi+1knGzKxIVZlkmkZl1ztsbOsY4kjMzEa2qkwyYxqyJLPJScbMrFBVmWTGNrglY2Y2GKo6ybglY2ZWrKpMMu4uMzMbHFWZZOpra6gv1bCxrXOoQzEzG9GqMskAjGkosbGtfajDMDMb0ao4ydSyyS0ZM7NCVW2SGdtQ66vLzMwKVrVJJmvJOMmYmRWpapPMWCcZM7PCVW2SGdNQYtM2n5MxMytS1SaZ+lIN2zq6hjoMM7MRrXqTTK2TjJlZ0ao7yXQ6yZiZFal6k0ypRFu7z8mYmRWp0CQj6VRJCyUtknRpD2VOkbRA0gOSbi0ynryGOrdkzMyKVlvUiiWVgK8CLweWAvMkXRcRD+bKTAC+BpwaEX+RNKWoeMrVl2po7wy6uoKaGg3WZs3MqkqRLZmTgEURsTgitgFXA2eVlXkj8NOI+AtARKwsMJ6d1NdmVXdrxsysOEUmmRZgSW58aZqWdygwUdItku6SdH6lFUm6SNJ8SfNbW1sHJLgGJxkzs8IVmWQq9UFF2XgtcAJwBvBK4J8kHbrLQhGXR8TciJjb3Nw8IMF1t2Ta2p1kzMyKUtg5GbKWy4zc+HRgeYUyqyJiE7BJ0m3AscAjBcYFuCVjZjYYimzJzAPmSDpQUj1wLnBdWZlrgRdIqpXUCJwMPFRgTNttPyfjH2SamRWmsJZMRHRIugS4ESgBV0bEA5IuTvMvi4iHJP0vcC/QBVwREfcXFVNefakEOMmYmRWpyO4yIuIG4IayaZeVjX8O+FyRcVTiloyZWfGq9xf/3Sf+O/yrfzOzolRtkmlwS8bMrHBVm2S2t2R8dZmZWWGqN8mU3JIxMyta1SYZd5eZmRWvapOMry4zMyte1SaZhtrsdzJtTjJmZoWp2iSzoyXjS5jNzIpS9UmmvbP8np1mZjZQqjbJ1JWym0T7BplmZsWp2iTjS5jNzIpXtUlGEnUluSVjZlagqk0yAHWlGtrdkjEzK0xVJ5n62hq3ZMzMClTVSaauVEO7k4yZWWGqOsnUl2rY1uFLmM3MilLdScbdZWZmharuJOMT/2ZmharqJFNX60uYzcyKVGiSkXSqpIWSFkm6tML8UyStk7Qg/X2syHjK+cS/mVmxaotasaQS8FXg5cBSYJ6k6yLiwbKiv4uIM4uKozf1pRrfhdnMrEBFtmROAhZFxOKI2AZcDZxV4PZ2W32tWzJmZkUqMsm0AEty40vTtHLPkXSPpF9JOqrAeHZR7+4yM7NCFdZdBqjCtPIfpfwZmBURGyWdDvwcmLPLiqSLgIsAZs6cOWAB1pVqfINMM7MCFdmSWQrMyI1PB5bnC0TE+ojYmIZvAOokTS5fUURcHhFzI2Juc3PzgAWYdZf5x5hmZkUpMsnMA+ZIOlBSPXAucF2+gKQDJCkNn5TiWV1gTDtxS8bMrFiFdZdFRIekS4AbgRJwZUQ8IOniNP8y4HXAOyV1AFuAcyNi0JoW9f6djJlZoYo8J9PdBXZD2bTLcsNfAb5SZAy9qXdLxsysUNX9i39fXWZmVqiqTjL+nYyZWbGqOslkLZmgq8tXmJmZFaGqk0x9bVb99i63ZszMilDdSaaUVd8n/83MilHVSaaulN2UwD/INDMrRlUnmfraEuCWjJlZUao6yexoyTjJmJkVoaqTTPeJf//q38ysGNWdZHzi38ysUNWdZLovYXZLxsysEFWdZOrckjEzK5STDD4nY2ZWlKpOMttP/LslY2ZWiOpOMqXuczL+MaaZWRGqO8n4xL+ZWaGqOsl0/xjT3WVmZsWo6iTjH2OamRWrupOML2E2MytUVSeZupLPyZiZFanQJCPpVEkLJS2SdGkv5U6U1CnpdUXGU86XMJuZFauwJCOpBHwVOA04EjhP0pE9lPsscGNRsfTELRkzs2IV2ZI5CVgUEYsjYhtwNXBWhXLvBn4CrCwwloq2X13m38mYmRWiyCTTAizJjS9N07aT1AK8BristxVJukjSfEnzW1tbByxASdSXatxdZmZWkCKTjCpMK28yfAH4UER09raiiLg8IuZGxNzm5uaBig/Izsu4u8zMrBi1Ba57KTAjNz4dWF5WZi5wtSSAycDpkjoi4ucFxrWTupLckjEzK0iRSWYeMEfSgcAy4FzgjfkCEXFg97Ckq4DrBzPBQHby3y0ZM7NiFJZkIqJD0iVkV42VgCsj4gFJF6f5vZ6HGSz1tT4nY2ZWlCJbMkTEDcANZdMqJpeIuKDIWHpSX1tDm1syZmaFqOpf/AOMriuxdVuv1x2YmdkecpKpK7Gl3UnGzKwITjL1TjJmZkXpV5KR9B5J45T5lqQ/S3pF0cENhtF1Jba4u8zMrBD9bclcGBHrgVcAzcDbgM8UFtUgckvGzKw4/U0y3b/ePx34dkTcQ+Vf9A87jfVuyZiZFaW/SeYuSTeRJZkbJTUBI+K631HuLjMzK0x/fyfzduA4YHFEbJY0iazLbNjz1WVmZsXpb0vmOcDCiFgr6c3AR4F1xYU1eBrrS3R0hW8tY2ZWgP4mma8DmyUdC3wQeBL4bmFRDaJRdSUANrvLzMxswPU3yXRERJA9dOyLEfFFoKm4sAZPY33WY7jVXWZmZgOuv+dkNkj6MPAW4AXpkcl1xYU1eEbXZ3nWJ//NzAZef1sy5wBtZL+XeYrsCZefKyyqQTTa3WVmZoXpV5JJieUHwHhJZwJbI2JEnJMZnbrLfIWZmdnA6+9tZd4A3Am8HngDcIek1xUZ2GDZ0ZLpGOJIzMxGnv6ek/kIcGJErASQ1Az8H/DjogIbLE2jsl2wcauTjJnZQOvvOZma7gSTrN6NZfdp3Ulmg5OMmdmA629L5n8l3Qj8dxo/h7InXg5XTaOyi+TWb20f4kjMzEaefiWZiPiApNcCzyO7MeblEfGzQiMbJGMb3JIxMytKf1syRMRPgJ8UGMuQKNWIsQ21bsmYmRWg1/MqkjZIWl/hb4Ok9X2tXNKpkhZKWiTp0grzz5J0r6QFkuZLev7eVGZPjRtV65aMmVkBem3JRMQe3zom3RXgq8DLgaXAPEnXRcSDuWK/Aa6LiJB0DHANcPiebnNPNY2qY4NbMmZmA67IK8ROAhZFxOKI2AZcTXbvs+0iYmO6JxrAGCAYAk1uyZiZFaLIJNMCLMmNL03TdiLpNZIeBn4JXFhpRZIuSt1p81tbWwc80KZRPidjZlaEIpNMpccz79JSiYifRcThwNnApyqtKCIuj4i5ETG3ubl5YKMExo2uc0vGzKwARSaZpcCM3Ph0YHlPhSPiNuBgSZMLjKmiCaPrWLNp22Bv1sxsxCsyycwD5kg6UFI9cC5wXb6ApEMkKQ0fD9ST3U1gUE0a08D6rR1+OqaZ2QDr9+9kdldEdEi6BLgRKAFXRsQDki5O8y8DXgucL6kd2AKck7sQYNBMGlsPwJpN25gybtRgb97MbMQqLMkARMQNlN1+JiWX7uHPAp8tMob+2G9MlmRWO8mYmQ2oEXGTy701KSWZZ3xexsxsQDnJsHNLxszMBo6TDLmWzMa2IY7EzGxkcZIBJjTWU6oRqza6JWNmNpCcZMjuxDylqYEV67YOdShmZiOKk0wydfwoVqzbMtRhmJmNKE4yydQJo3nKLRkzswHlJJNMHTeK5eu2MAS/BTUzG7GcZJKpE0aztb2LtZt9N2Yzs4HiJJNMHZ/90t8n/83MBo6TTLIjyfjkv5nZQHGSSaZNGA3AcrdkzMwGjJNMMnlsA7U14im3ZMzMBoyTTFKqEfuPG8WKtW7JmJkNFCeZnJYJo1myZvNQh2FmNmI4yeQcOHkMj6/aNNRhmJmNGE4yOQc2j2HVxm2s2+LfypiZDQQnmZyDJo8BcGvGzGyAOMnkHNQ8FoDFrRuHOBIzs5HBSSZn5qRGSjVicatbMmZmA6HQJCPpVEkLJS2SdGmF+W+SdG/6u13SsUXG05f62hpmTBzN4lVuyZiZDYTCkoykEvBV4DTgSOA8SUeWFXsceFFEHAN8Cri8qHj666DmsW7JmJkNkCJbMicBiyJicURsA64GzsoXiIjbI2JNGv0TML3AePrlkCljWbxqE+2dXUMdipnZsFdkkmkBluTGl6ZpPXk78KtKMyRdJGm+pPmtra0DGOKujm4Zz7aOLh55ekOh2zEzqwZFJhlVmFbxiWCSXkyWZD5UaX5EXB4RcyNibnNz8wCGuKtjWsYDcO/SdYVux8ysGhSZZJYCM3Lj04Hl5YUkHQNcAZwVEasLjKdfZu3XyLhRtU4yZmYDoMgkMw+YI+lASfXAucB1+QKSZgI/Bd4SEY8UGEu/SeKY6RO4b9naoQ7FzGzYKyzJREQHcAlwI/AQcE1EPCDpYkkXp2IfA/YDviZpgaT5RcWzO541fTwLn9rA1vbOoQ7FzGxYqy1y5RFxA3BD2bTLcsPvAN5RZAx74rgZE2jvDO5bto4TZ08a6nDMzIYt/+K/gpMPnIQEty8a8lNEZmbDmpNMBRMa6zlq2jhue7TYy6XNzEY6J5kevPLIA7jryTWs8OOYzcz2mJNMD848dhoAv7x3xRBHYmY2fDnJ9ODAyWM4umUcv3CSMTPbY04yvTjzmGncs2QtS57ZPNShmJkNS04yvTjjWVMBuHbBsiGOxMxseHKS6cWMSY28YM5kvvX7x9mwtX2owzEzG3acZPrw/lccxprN7fxo3pK+C5uZ2U6cZPpw7IwJnHzgJL5x22LWuzVjZrZbnGT64SNnHMHqjW18/saFQx2Kmdmw4iTTD8dMn8D5z5nN9/70JLcsXDnU4ZiZDRtOMv30oVMP57D9m/j7Hy3wJc1mZv3kJNNPo+tLfO1Nx9MV8JZv3UHrhrahDsnMbJ/nJLMbDmoey5UXzOXp9W287rLbeWLVpqEOycxsn+Yks5tOmDWJ77/jZNZvaee1X7+d3z+6aqhDMjPbZznJ7IETZk3kJ+98LhMa63jzt+7gE794wE/RNDOrwElmDx3UPJbr3/0CLnjubL79hyc4/Uu/4+aHVxIRQx2amdk+w0lmL4yuL/HxVx/FD95xMu2dXbztqnn89ddv53ePtjrZmJnhJDMgnnfIZH7zD6fwb695Fk+v28pbvnUn53zjT/zxsdVONmZW1QpNMpJOlbRQ0iJJl1aYf7ikP0pqk/T+ImMpWn1tDW88eSY3f+AUPnnWUTyxehPnffNPvOK/buPndy9jW0fXUIdoZjboVNQ3bUkl4BHg5cBSYB5wXkQ8mCszBZgFnA2siYjP97XeuXPnxvz58wuJeSBtbe/k2gXL+NbvH+eRpzcyaUw9rz2+hXNPmsnBzWOHOjwzqzKS7oqIuYO93doC130SsCgiFgNIuho4C9ieZCJiJbBS0hkFxjEkRtWVOOfEmbz+hBnc9mgrV9+5hG//4Qm++bvHmTtrIs89ZDIXPHc2k8bUD3WoZmaFKTLJtAD5++MvBU7ekxVJugi4CGDmzJl7H9kgqqkRpxw2hVMOm8LKDVv58V1L+cU9K/jybx/lm7ct5rSjD+DsZ7fwvEMmU6rRUIdrZjagikwylT4x96hvLiIuBy6HrLtsb4IaSlOaRvGuUw7hXaccwqKVG/jW7x/n+ntX8NO7l9Hc1MBZx07j7Ge3cNS0cUhOOGY2/BWZZJYCM3Lj04HlBW5vWDlkShOf/utj+OdXHcUtC1fy0z8v4zt/fIIrfv84h0wZy9nHTeOs41qYMalxqEM1M9tjRSaZecAcSQcCy4BzgTcWuL1haVRdiVOPnsqpR09l7eZt/PK+FVx793I+f9MjfP6mR5g7ayJnP7uFM541lYk+f2Nmw0xhV5cBSDod+AJQAq6MiH+VdDFARFwm6QBgPjAO6AI2AkdGxPqe1jlcri7bW0vXbObaBcv5+d3LeHTlRupK4kWHNnP2s1t42RH7M6quNNQhmtkwMlRXlxWaZIpQLUmmW0Tw4Ir1XLtgOdcuWMbT69sY21DLqUcfwNnHtfCcg/fzBQNm1icnmX6qtiST19kV3LF4NT9fsIxf3fcUG9o6mNLUwBnHTOVVx07j2TMm+IIBM6vISaafqjnJ5G1t7+S3D6/k53cv45ZHWtnW0UXLhNGceexUXnXMNF+hZmY7cZLpJyeZXW3Y2s6vH3yaX9yznN89uoqOruDAyWM4M7VwDt2/aahDNLMh5iTTT04yvVuzaRs3PvAUv7h3OX98bDVdAYfuP5YznjWNlx4xhSOnjqPG53DMqo6TTD85yfRf64Y2fnX/Cn5xz3LmPbEGgOamBk45tJkXHz6F58+ZzLhRdUMcpZkNBieZfnKS2TOrNrZx68JWbl64ktseaWX91g5qa8QJsyZyymFTOPmgSRw1bRwNtb402mwkcpLpJyeZvdfR2cXdS9Zy88MruXlhKw+tyH6WVF9bwzEt4zlh1kSOnzWR42dOpLmpYYijNbOB4CTTT04yA2/lhq38+ck13JX+7l+2nm2d2fNvZu3XyAkzs6RzwqyJHLp/k3+XYzYMOcn0k5NM8do6Orl/2frtiWf+k2tYtbENgLENtRw3Y8L2pHPcjAmMH+3zOmb7OieZfnKSGXwRwdI1W7a3dO56cg0PP7WernTotEwYzRFTmzhi6jiOmDqOww9oYtZ+Y9ziMduHjMSHltkIIYkZkxqZMamRs5/dAsDGtg7uWbKWe5au5eEVG3hoxXpuXthKZ8o8o+tKHHpAE4fv38QhU8Zy8JQxHNLcRMvE0U4+ZlXELRkbMFvbO1m0ciMPrVjPQys28PBT63nk6Q2s2rhte5n62hoOmjyGg6eM5eDmsRzcPIaDm8cye/IYxjb4O49ZUdySsWFvVF2Jo1vGc3TL+J2mr928jcdaN/LYyk0sat3IYys3cv+ydfzqvhXbu9wg+w3P7P0amb3fGGZPHsOs/RqZMbGRlomj2W9MvW+TYzYMOclY4SY01nPCrEmcMGvSTtO3tnfyxOpNLG7dxOOrNvHk6k08sWoztzzSSutdS3cqO6quhukTG2mZMJrpE0fTMnE00yc2Mn3iaKaNH83ksfXUlmoGs1pm1g9OMjZkRtWVOPyAcRx+wLhd5m1q6+DJ1ZtZtnYLS9dsZumaLSxbs4Wlazdz79K1rNncvlN5CSY11tPc1MCUcaNoHtvAlHENTGlqyKY1jUr/GxjjbjmzQeN3m+2TxjTUcuS0cRw5bdcEBNmFB8vWbGHZ2s0sX7uV1g1trNzQRuuGbPjRpzfQuqGNjq5dzzmOqS/tlHiyxNTApMZ6xo+uY/zoOsal/+Mb62hqqHVXndkecpKxYWlsQy2HHdDEYQf0fIfprq5g7ZZ2VqbEs3J9dyJq2z7toRXrufWRNja2dfS4nhrBuNF1TChPQGV/ExqzeeNG1TGmoZYxDSXG1NfSWF9ykrKq5SRjI1ZNjZg0pp5JY+o5/IDey27e1sGaze2s29zOui3Z3/otO4bXbtnGui0d28eXrtmyfbizQmspT4LGuhJjGmoZ21BLY0o+WSKqZWxDicY03lhfYlRtDaPqSjTU1dBQW2JU+t9QWzZeV8Oo9L++VOO7a9s+yUnGDGisr6WxvpaWCaN3a7mIYGPbjuSzbks7G7Z2sKmtg03bOtnU1sHmtg42tnWyeVsHG9s62Lytk41tHazcsJVNq7Iy3eX3Rn2pZntiaqit2SkJNXQnrtod87eP71Ru13nd02pLNdTWiLpSDbUlUVeT/a8tifrSzvP9WyjrVmiSkXQq8EWgBFwREZ8pm680/3RgM3BBRPy5yJjMBpIkmkbV0TSqjukT925dXV3B1o5O2tq7tv9v6+iiraOTre3Z//J5W9s7t5fZaXynctn/NZu2pbL5cp1s7ejqszW2uyR2JKEaUV9bQ20ar0vJqLZUQ12aX1eq2Z68amvS9FSuVKOd/tdsH98xv1ShXKmsTG0pTVO2jpKycYmdptdIlGqgRt3D+f9sX7ZGoqaG7fO7y5QkVMPO698+XH3Jt7AkI6kEfBV4ObAUmCfpuoh4MFfsNGBO+jsZ+Hr6b1Z1amqUWlSDv+2OzvKklUtuaVpHVxftnUFHZ+SGu2jvCtp7md/RFWzr7MqGO4P2rrRcKtfRmc3fvK2Djq7YabmOri66uqCjK0uEHV1BZ2fQGWk4/Q0nOxJalsh2JLddE1ZNSlY1ypLVeSfN5B0vOGioq7BbimzJnAQsiojFAJKuBs4C8knmLOC7kd124E+SJkiaGhErCozLzMrUpu6u4Xh5d0RKNul/dyLanoSiezyXqLqCruj+T2446OqCzugezk0PcsNBZ1fW+uyKbBs7ytLLurvj3DnuSOvOhruT545lg2x48tjh9+iNIo+oFmBJbnwpu7ZSKpVpAZxkzKxfpKwrbPilx+pQ5E+kK3U+lrdr+1MGSRdJmi9pfmtr64AEZ2ZmxSsyySwFZuTGpwPL96AMEXF5RMyNiLnNzc0DHqiZmRWjyCQzD5gj6UBJ9cC5wHVlZa4Dzlfmr4B1Ph9jZjZyFNaNGREdki4BbiS7hPnKiHhA0sVp/mXADWSXLy8iu4T5bUXFY2Zmg6/Qc2URcQNZIslPuyw3HMD/KzIGMzMbOr43upmZFcZJxszMCuMkY2ZmhVF2WmT4kNQKPLmHi08GVg1gOMOB61wdXOfqsDd1nhURg/4bkGGXZPaGpPkRMXeo4xhMrnN1cJ2rw3Css7vLzMysME4yZmZWmGpLMpcPdQBDwHWuDq5zdRh2da6qczJmZja4qq0lY2Zmg8hJxszMClM1SUbSqZIWSlok6dKhjmegSLpS0kpJ9+emTZL0a0mPpv8Tc/M+nPbBQkmvHJqo946kGZJulvSQpAckvSdNH7H1ljRK0p2S7kl1/kSaPmLrDNlj3CXdLen6ND6i6wsg6QlJ90laIGl+mjZ86x3pcZ8j+Y/sLtCPAQcB9cA9wJFDHdcA1e2FwPHA/blp/w5cmoYvBT6bho9MdW8ADkz7pDTUddiDOk8Fjk/DTcAjqW4jtt5kD/gbm4brgDuAvxrJdU71+Afgh8D1aXxE1zfV5Qlgctm0YVvvamnJnAQsiojFEbENuBo4a4hjGhARcRvwTNnks4DvpOHvAGfnpl8dEW0R8TjZIxZOGow4B1JErIiIP6fhDcBDZI/tHrH1jszGNFqX/oIRXGdJ04EzgCtyk0dsffswbOtdLUmmBViSG1+apo1U+0d6+Fv6PyVNH3H7QdJs4Nlk3+xHdL1T19ECYCXw64gY6XX+AvBBoCs3bSTXt1sAN0m6S9JFadqwrXehz5PZh6jCtGq8dntE7QdJY4GfAO+NiPVSpeplRStMG3b1johO4DhJE4CfSTq6l+LDus6SzgRWRsRdkk7pzyIVpg2b+pZ5XkQslzQF+LWkh3spu8/Xu1paMkuBGbnx6cDyIYplMDwtaSpA+r8yTR8x+0FSHVmC+UFE/DRNHvH1BoiItcAtwKmM3Do/D3i1pCfIurdfIun7jNz6bhcRy9P/lcDPyLq/hm29qyXJzAPmSDpQUj1wLnDdEMdUpOuAt6bhtwLX5qafK6lB0oHAHODOIYhvryhrsnwLeCgi/jM3a8TWW1JzasEgaTTwMuBhRmidI+LDETE9ImaTvV9/GxFvZoTWt5ukMZKauoeBVwD3M5zrPdRXHgzWH3A62VVIjwEfGep4BrBe/w2sANrJvtW8HdgP+A3waPo/KVf+I2kfLAROG+r497DOzyfrErgXWJD+Th/J9QaOAe5Odb4f+FiaPmLrnKvHKey4umxE15fsCth70t8D3Z9Vw7nevq2MmZkVplq6y8zMbAg4yZiZWWGcZMzMrDBOMmZmVhgnGTMzK4yTjO2zJIWk/8iNv1/Sxwdo3VdJet1ArKuP7bw+3S365qK3VbbdCyR9ZTC3aVaJk4zty9qAv5Y0eagDyZNU2o3ibwfeFREvLioes32Zk4ztyzrInmn+9+Uzylsikjam/6dIulXSNZIekfQZSW9Kz2K5T9LBudW8TNLvUrkz0/IlSZ+TNE/SvZL+NrfemyX9ELivQjznpfXfL+mzadrHyH44epmkz1VY5gO57XQ/H2a2pIclfSdN/7GkxjTvpenZKvcpe45QQ5p+oqTblT1r5s7uX4wD0yT9b3oGyb/n6ndVivM+SbvsW7OBVC03yLTh66vAvd0fkv10LHAE2SMQFgNXRMRJyh5u9m7gvancbOBFwMHAzZIOAc4H1kXEielD/A+SbkrlTwKOjuyW6ttJmgZ8FjgBWEN2B92zI+KTkl4CvD8i5pct8wqyW4CcRHaTw+skvRD4C3AY8PaI+IOkK4F3pa6vq4CXRsQjkr4LvFPS14AfAedExDxJ44AtaTPHkd2hug1YKOnLZHfvbYmIo1McE3Zjv5rtNrdkbJ8WEeuB7wJ/txuLzYvsmTNtZLfb6E4S95Ellm7XRERXRDxKlowOJ7tX1PnKbql/B9ntPOak8neWJ5jkROCWiGiNiA7gB2QPk+vNK9Lf3cCf07a7t7MkIv6Qhr9P1ho6DHg8Ih5J07+TtnEYsCIi5kG2v1IMAL+JiHURsRV4EJiV6nmQpC9LOhVY30ecZnvFLRkbDr5A9kH87dy0DtKXpHTDzPrcvLbccFduvIudj/nyeyoFWavi3RFxY36GstvNb+ohvh6fMdALAZ+OiG+UbWd2L3H1tJ6e7g2V3w+dQG1ErJF0LPBK4P8BbwAu3L3QzfrPLRnb50XEM8A1ZCfRuz1B1j0F2dMB6/Zg1a+XVJPO0xxEdoPBG8m6oeoAJB2a7obbmzuAF0manC4KOA+4tY9lbgQuVPZMHCS1KHt+CMBMSc9Jw+cBvye74/Ls1KUH8Ja0jYfJzr2cmNbTJKnHL4/pIoqaiPgJ8E9kj+42K4xbMjZc/AdwSW78m8C1ku4kuyttT62M3iwk+6DeH7g4IrZKuoKsS+3PqYXUyo5H3VYUESskfRi4maxlcUNEXNvHMjdJOgL4Y7YZNgJvJmtxPAS8VdI3yO66+/UU29uA/0lJZB5wWURsk3QO8GVljwDYQvYYgJ60AN+W1P0F88O9xWm2t3wXZrN9SOouu777xLzZcOfuMjMzK4xbMmZmVhi3ZMzMrDBOMmZmVhgnGTMzK4yTjJmZFcZJxszMCvP/Ae+kgLNCiBxzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the loss for ANN\n",
    "ANN_Clf.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbe8c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to represent node in the decision trees\n",
    "class node():\n",
    "    \n",
    "    def __init__(self, value = None, right_child = None, left_child = None, \n",
    "                 info_gain = None, feature_num = None, threshold = None):\n",
    "        \n",
    "        #in case of leaf node\n",
    "        self.value = value\n",
    "        \n",
    "        #in case if node is a tree\n",
    "        self.right_child = right_child\n",
    "        self.left_child = left_child\n",
    "        self.info_gain = info_gain\n",
    "        self.feature_num = feature_num\n",
    "        self.threshold = threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d151f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for decision tree\n",
    "class Decision_Tree_Classifier():\n",
    "    \n",
    "    def __init__(self, criterion = \"gini\", max_depth = 2, min_samples_split = 2):\n",
    "        self.root = None\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "    \n",
    "    #method to calculate entropy\n",
    "    def entropy(self, y):\n",
    "        \n",
    "        unique_val = np.unique(y)\n",
    "        total_length = len(y)\n",
    "        entropy = 0\n",
    "        for cls in unique_val:\n",
    "            prob = len(y[y == cls]) / total_length\n",
    "            entropy += -prob * np.log2(prob)\n",
    "        return entropy\n",
    "    \n",
    "    #method to calculate Gini Index\n",
    "    def gini_index(self, y):\n",
    "        ''' function to compute gini index '''\n",
    "        \n",
    "        class_labels = np.unique(y)\n",
    "        total_length = len(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / total_length\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "    \n",
    "    #method to calculate information gain\n",
    "    def info_gain(self, criterion, root, right_child, left_child):\n",
    "        \n",
    "        parent_length = len(root)\n",
    "        right_weight = len(right_child)/parent_length\n",
    "        left_weight = len(left_child)/parent_length\n",
    "        \n",
    "        if criterion == 'gini':\n",
    "            \n",
    "            r_child_value = self.gini_index(right_child)\n",
    "            l_child_value = self.gini_index(left_child)\n",
    "            root_value    = self.gini_index(root)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            r_child_value = self.entropy(right_child)\n",
    "            l_child_value = self.entropy(left_child)\n",
    "            root_value    = self.entropy(root)\n",
    "        #print(root_value, right_weight, r_child_value, left_child, l_child_value)\n",
    "        info_gain = root_value - (right_weight * r_child_value) - (left_weight * l_child_value)\n",
    "        #print(info_gain)\n",
    "        return info_gain\n",
    "    \n",
    "    #method to split the attribute based on athreshold\n",
    "    def split(self, data, attribute_num, threshold):\n",
    "        \n",
    "        right_data = []\n",
    "        left_data = []\n",
    "        \n",
    "        for row in data:\n",
    "            \n",
    "            if row[attribute_num] > threshold:\n",
    "                \n",
    "                right_data.append(row)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                left_data.append(row)\n",
    "                \n",
    "        return np.array(left_data), np.array(right_data)\n",
    "    \n",
    "    #method to get the best split anong the possible splits\n",
    "    def get_best_split(self, data, num_features):\n",
    "        \n",
    "        best_split_info = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        \n",
    "        for feature in range(num_features):\n",
    "            \n",
    "            feature_data = data[:, feature]\n",
    "            \n",
    "            #getting the unique values in the attribute\n",
    "            unique_val = np.unique(feature_data)\n",
    "            \n",
    "            for threshold in unique_val:\n",
    "                \n",
    "                #splitting the data using the given threshold\n",
    "                left_data, right_data = self.split(data, feature, threshold)\n",
    "                \n",
    "                if len(left_data) > 0 and len(right_data) > 0:\n",
    "                    \n",
    "                    #print(np.shape(data), np.shape(left_data), np.shape(right_data))\n",
    "                    \n",
    "                    label, left_label, right_label = data[:, -1], left_data[:, -1], right_data[:, -1]\n",
    "                    \n",
    "                    #calculating the info gain for the current split\n",
    "                    current_info_gain = self.info_gain(self.criterion, label, left_label, right_label)\n",
    "                    #print(current_info_gain)\n",
    "                    if current_info_gain > max_info_gain:\n",
    "                        \n",
    "                        max_info_gain = current_info_gain\n",
    "                        best_split_info['info_gain'] = current_info_gain\n",
    "                        \n",
    "                        best_split_info['best_feature'] = feature\n",
    "                        best_split_info['threshold'] = threshold\n",
    "                        \n",
    "                        best_split_info['right_child'] = right_data\n",
    "                        best_split_info['left_child']  = left_data\n",
    "                        \n",
    "        return best_split_info  \n",
    "    \n",
    "    #creating the tree\n",
    "    def build_tree(self, data, depth = 0):\n",
    "        \n",
    "        Labels = data[:, -1]\n",
    "        \n",
    "        num_ex, num_features = np.shape(data[:, :-1])\n",
    "        \n",
    "        if depth <= self.max_depth and num_ex >= self.min_samples_split:\n",
    "            \n",
    "            best_split =  self.get_best_split(data, num_features)\n",
    "            \n",
    "            if best_split['info_gain'] > 0:\n",
    "                \n",
    "                left_child = self.build_tree(best_split['left_child'], depth + 1)\n",
    "                right_child = self.build_tree(best_split['right_child'], depth + 1)\n",
    "                \n",
    "                return node(None, right_child, left_child, best_split['info_gain'], best_split['best_feature'], best_split['threshold'])\n",
    "        \n",
    "        return node(self.leaf_value_caluculator(Labels))\n",
    "    \n",
    "    #calculating the label in the leaf\n",
    "    def leaf_value_caluculator(self, Y):\n",
    "        \n",
    "        unique_vals = np.unique(Y)\n",
    "        \n",
    "        majority_vote = -1\n",
    "        leaf_value = None\n",
    "        \n",
    "        for val in unique_vals:\n",
    "            \n",
    "            cnt =np.sum(Y == val)\n",
    "            \n",
    "            #getting the majority vote\n",
    "            if cnt > majority_vote:\n",
    "                leaf_value = val\n",
    "                majority_vote = cnt\n",
    "                \n",
    "        return leaf_value\n",
    "    \n",
    "    \n",
    "    #training the model\n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "    \n",
    "    #predicting - traversing through the tree\n",
    "    def predict(self, X):\n",
    "        \n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions\n",
    "    \n",
    "    #predicting a data point\n",
    "    def make_prediction(self, x, tree):\n",
    "        \n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.feature_num]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left_child)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right_child)\n",
    "    \n",
    "    #printing the tree\n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_num), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left_child, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right_child, indent + indent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b011ff82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.592580556869507\n"
     ]
    }
   ],
   "source": [
    "#creating the decision tree object\n",
    "start = time.time()\n",
    "classifier_DT = Decision_Tree_Classifier(criterion = \"entropy\", min_samples_split=2,  max_depth=5)\n",
    "\n",
    "#training the decision tree\n",
    "classifier_DT.fit(X_train_arr,Y_train_arr)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a38fdb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on testing data\n",
    "pred_DT = classifier_DT.predict(X_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ace24108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for Decision trees is  [[848, 0], [3, 774]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for Decision Trees\n",
    "confusion_matrix_DT = confusion_matrix(Y_test, pred_DT)\n",
    "print(\"The confusion matrix for Decision trees is \", confusion_matrix_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe718079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[774,   3],\n",
       "       [  0, 848]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM(Y_test, pred_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "025fcd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of mushroom classification on test data using Decision Trees is 0.9981538461538462\n",
      "The Precision of mushroom classification on test data using Decision Trees  is 0.9964747356051704\n",
      "The Recall of mushroom classification on test data using Decision Trees  is 1.0\n",
      "The F1 score of mushroom classification on test data using Decision Trees is 0.998234255444379\n"
     ]
    }
   ],
   "source": [
    "#calculating the metrics for Decision Trees\n",
    "accuracy_DT = Accuracy(Y_test, pred_DT)\n",
    "precision_DT = Precision(Y_test, pred_DT)\n",
    "recall_DT = Recall(Y_test, pred_DT)\n",
    "F1_DT = F1_Score(Y_test, pred_DT)\n",
    "print(f\"The accuracy of mushroom classification on test data using Decision Trees is {accuracy_DT}\")\n",
    "print(f\"The Precision of mushroom classification on test data using Decision Trees  is {precision_DT}\")\n",
    "print(f\"The Recall of mushroom classification on test data using Decision Trees  is {recall_DT}\")\n",
    "print(f\"The F1 score of mushroom classification on test data using Decision Trees is {F1_DT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f95bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
